{
    "chunks": [
        {
            "id": 1,
            "content": "<p>Example: There are $2 7$ pieces of fruit in a barrel, and twice as many oranges as apples. How many apples and oranges are in the barrel?</p>\n<p>How to solve this conundrum? We can re-write the question mathematically as follows:</p>\n<p>This is an example of a Linear System. It's a collection of eouations in which\nvariables are multiplied by constants and summed, and no variables are multiplied together: There are no powers of x or $\\mathbf{y}$ greater than one, no fractional or negative powers of $\\mathbf{X}$ or $\\mathbf{y}$ , and no places where $\\mathbf{X}$ and $\\mathbf{y}$ are multiplied together.</p>\n<p>$\\mathrm{S}$ o, to say that we are interested in linear algebra is to say we're interested in just equations and transformations where the outputs are just a weighted sum of the inputs. For example, the equation for a line,</p>\n<p>is linear because every term summed to compute $\\mathbf{y}$ is a constant multiplied by an input, $\\mathbf{X}$ is weighted by m. An equation like $\\mathbf{y}=\\mathbf{x}^{2}$ is not linear because the\nsquaring operation is more complex than just a weight multiplied by an input. In general, the equation</p>"
        },
        {
            "id": 2,
            "content": "<p>Linear equations are a special case of algebra generally, but they're a special case that we can often analyze quickly and deeply, compared to other kinds of\nequations. We can casily predict what physical systems will do in the long run if the equations are linear, but things get much harder to predict when things are nonlinear. For ease of computation, we sometimes model systems as linear even when they technically should have some nonlinear terms.</p>\n<h2>Introduction to Linear Algebra</h2>\n<p>$$\n\\mathrm{W h o ~ l o v e s ~ p u z z l e s ~ h e r e?}\n$$</p>\n<p>Let's take a small example, albeit a simple one:</p>\n<p>$$\n\\begin{array} {c} {\\mathbf{x}+\\mathbf{y}=2 7} \\ {\\mathbf{y}=2 \\mathbf{x}} \\ \\end{array}\n$$</p>\n<p>$$\n{\\bf y}=\\mathrm{m} {\\bf x}\n$$</p>\n<p>$$\n\\mathbf{y}=\\mathbf{a}<em>{1} \\mathbf{x}</em>{1}+\\mathbf{a}<em>{2} \\mathbf{x}</em>{2}+\\ldots+\\mathbf{a}<em>{\\mathrm{n}} \\mathbf{x}</em>{\\mathrm{n}}\n$$</p>\n<p>is linear, assuming the a.'s are constant and the $\\mathrm{X_{i}^{\\prime} s}$ are the inputs</p>"
        },
        {
            "id": 3,
            "content": "<h2>Why restrict ourselves to Linear Algebra? Machine learning. Machine learning often makes use of linear algebra in proving learners have good properties, and the steps of a machine learning algorithm may make use of linear algebra.</h2>\n<p>Regression. Trying to fit curves to points involves linear algebra.\nGraph algorithms. Graphs are abstractions that can represent relations\nbetween things, such as Internet connections or who is the president of what country, and some big data databases store graph data to be able to answer queries about it. Graphs can be mathematically modeled as matrices, a tool of linear algebra that we'll study in great depth. This can reveal things like what the most important or central nodes are in a graph.\nVisualization. Linear algebra can take complex datasets and find ways to render them that make interesting relationships between variables stand out.</p>\n<p>Visualization. Linear algebra can take complex datasets and find ways to render them that make interesting relationships between variables stand out.</p>"
        },
        {
            "id": 4,
            "content": "<p>we can solve the system by manipulating the ccuations involved. First, notice that the second equation is the same $\\mathrm{a s-2 x+y=0.}$ . Then if you subtract the second equation from the first, you get on the left side $\\mathrm{x+y}-(-2 \\mathrm{x+y} )=3 \\mathrm{x}$ , and on the left side you get $2 7-0=2 7$ . Then $3 {\\bf x}=2 7$ , so we learn that ${\\bf x}=9$ . Using the\nsecond equation, we then see that $\\mathbf{y}=1 8$ . Then there are $9$ apples and 18 oranges. Let's do it again, by working with the list of equations as an object in itself. First, we rewrite the equations tidily:</p>\n<p>The square list of numbers is an example of a matrix. We can multiply the matrix by the vector to get back the linear system using the following rule for multiplying matrices by vectors:</p>\n<p>Linear algebra comes up in the following data science domains:</p>\n<p>Now, let's go back to our example:</p>\n<p>$$\n\\begin{array} {c} {\\mathrm{x}+\\mathrm{y}=2 7} \\ {\\mathrm{y}=2 \\mathrm{x}} \\ \\end{array}\n$$</p>\n<p>$$\n\\mathrm{x+y=2 7} \\, 2 \\mathrm{x-y=0}\n$$</p>\n<p>We can express this set of equations with a matrix as follows:</p>\n<p>$$"
        },
        {
            "id": 5,
            "content": "<p>$$\n\\left( \\begin{matrix} {1} &amp; {1} \\ {2} &amp; {-1} \\ \\end{matrix} \\right) \\left( \\begin{matrix} {x} \\ {y} \\ \\end{matrix} \\right)=\\left( \\begin{matrix} {2 7} \\ {0} \\ \\end{matrix} \\right)\n$$</p>\n<p>The matrix is an example of a Linear Transformation, because it takes one vector and turns it into another in a 1inear\" way. Our next task is to solve linear systems. We'll learn a general method called Gaussian Elimination.</p>\n<p>$\\mathrm{A}$ useful shorthand for a linear system is an Augmented Matrix , which looks like this for the lincar system we've been dealing with:</p>\n<p>$$\n\\left( \\begin{matrix} {a} &amp; {b} \\ {c} &amp; {d} \\ \\end{matrix} \\right) \\left( \\begin{matrix} {x} \\ {y} \\ \\end{matrix} \\right)=\\left( \\begin{matrix} {a x+b y} \\ {c x+d y} \\ \\end{matrix} \\right)\n$$</p>\n<h2>Gaussian Elimination</h2>\n<p>Revisiting our previous example, because why not?</p>\n<p>$$\n\\mathrm{x+y=2 7} \\, 2 \\mathrm{x-y=0}\n$$</p>\n<p>$$\n\\mathrm{A n d ~ w e ~ g o t :}\n$$</p>\n<p>$$\n\\mathrm{x}=9 \\strut\\mathrm{y}=1 8\n$$</p>\n<p>We learne</p>\n<p>ed to write the linear system using a matrix and two vectors like so:</p>\n<p>$$"
        },
        {
            "id": 6,
            "content": "<p>$$\n\\left( \\begin{matrix} {1} &amp; {1} \\ {2} &amp; {-1} \\ \\end{matrix} \\right) \\left( \\begin{matrix} {x} \\ {y} \\ \\end{matrix} \\right)=\\left( \\begin{matrix} {2 7} \\ {0} \\ \\end{matrix} \\right)\n$$</p>\n<p>Likewise, we can write the solution as:</p>\n<p>$$\n\\left( \\begin{matrix} {1} &amp; {0} \\ {0} &amp; {1} \\ \\end{matrix} \\right) \\left( \\begin{matrix} {x} \\ {y} \\ \\end{matrix} \\right)=\\left( \\begin{matrix} {9} \\ {1 8} \\ \\end{matrix} \\right)\n$$</p>\n<p>The matrix $I=\\left( \\begin{matrix} {1} &amp; {0} \\ {0} &amp; {1} \\ \\end{matrix} \\right)$ is called the Idenify Mairic. You can check that if u is any vector, then $\\hat{I} \\boldsymbol{v}=\\boldsymbol{v}$ </p>\n<p>$$\n\\left( \\begin{matrix} {1} &amp; {1} &amp; {2 7} \\ {2} &amp; {-1} &amp; {0} \\ \\end{matrix} \\right)\n$$</p>\n<p>The solution to the linear system looks like this:</p>\n<p>$$\n\\left( \\begin{array} {c c | c} {1} &amp; {0} &amp; {9} \\ {0} &amp; {1} &amp; {1 8} \\ \\end{array} \\right)\n$$</p>\n<p>Let's look at a general Augmented Matrix Notation: The number of equations in the linear system is the number of rows r in the\naugmented matrix, and the number of columns k in the matrix left of the vertical line is the number of unknowns.</p>"
        },
        {
            "id": 7,
            "content": "<p>Elimination is a set of rules for taking a general augmented matrix and turning it into a very simple augmented matrix consisting of the identity matrix on the left and a bunch of numbers (the solution) on the right.</p>\n<p>There are three valid moves we could do (in general) in transforming these\nequations. This will seem like review, but Gaus-Jordan elimination is an\nalgorithm for applying them in a specific order to get to a solution, without really thinking about it.</p>\n<p>Multiply by a scalar - Replace one of the equations by the same equation, multiplied by a nonzero constant on both sides.\nRow combination - Replace an equation with the sum of that equation and a (nonzero) multiple of another ecuation.\nSwapping - Swap two equations in the order that we list them. This doesn't seem to do much for us right now, but it'll be worth remembering later on that this should lead to the same answer as if we hadn't swapped..</p>\n<p>The term row combination might seem a little strange - why not \"ecuation\ncombination'\"? - so before describing Gauss's method, we should describe a nice shorthand for systems of equations. $\\mathrm{A}$ matrix, plural matrices, lists just the"
        },
        {
            "id": 8,
            "content": "coefficients of the equations, arranged in a square or rectangle. $\\mathrm{A}$ typical matrix lists just the coefficients on one side, while an augmented matrix also gives the constants on the other side, separated by a line from the rest of the matrix. For example, we can represent the system of equations for our example as the\naugmented matrix:</p>\n<p>$$\n\\left( \\begin{matrix} {a_{1}^{1}} &amp; {a_{2}^{1}} &amp; {\\cdots} &amp; {a_{k}^{1}} &amp; {b^{1}} \\ {a_{1}^{2}} &amp; {a_{2}^{2}} &amp; {\\cdots} &amp; {a_{k}^{2}} &amp; {b^{2}} \\ {\\vdots} &amp; {\\vdots} &amp; {} &amp; {\\vdots} &amp; {\\vdots} \\ {a_{1}^{r}} &amp; {a_{2}^{r}} &amp; {\\cdots} &amp; {a_{k}^{r}} &amp; {b^{r}} \\ \\end{matrix} \\right)\n$$</p>\n<h2>Idea behind Gaussian elimination:</h2>\n<h2>How is it done?</h2>"
        },
        {
            "id": 9,
            "content": "<p>To do: Try and apply the above steps to our example!! Gauss-Jordan elimination describes a particular strategy for solving linear systems of equations, and we can think about applying it to either the cquations or their representation as an augmented matrix. Let n be the number of variables. Gauss-Jordan elimination moves from one variable to the next and performs operations that zero out that term for all later equations.</p>\n<p>f we apply this approach to an augmented matrix, then if a unique solution to the equations exists, the final result on the left would be a matrix with 1's along the diagonal and zeros elsewhere (remember $\\boldsymbol{D}$ , and the numbers on the right would be the solution to the original equations.</p>\n<p>The end result of this algorithm is a matrix in reduced row echelon form (RREF)</p>\n<p>It often happens that two mathematical objects will appear to be different but in fact are exactly the same. The best-known example of this are fractions.</p>\n<p>$$\n\\left( \\begin{matrix} {1} &amp; {1} &amp; {2 7} \\ {2} &amp; {-1} &amp; {0} \\ \\end{matrix} \\right)\n$$</p>\n<h2>Wait, what is RREF??</h2>\n<h2>Let's dig a little deeper!</h2>\n<p>$$"
        },
        {
            "id": 10,
            "content": "<p>$$\n\\mathrm{E g :} \\mathrm{} 1 / 2 \\mathrm{~ a n d ~} 6 / 1 2.\n$$</p>\n<p>Do you see how they are similar?</p>\n<p>In our running example, we've noticed that the two augmented matrices</p>\n<p>$$\n\\left( \\begin{array} {c c | c} {1} &amp; {1} &amp; {2 7} \\ {2} &amp; {-1} &amp; {0} \\ \\end{array} \\right), \\qquad\\left( \\begin{array} {c c | c} {1} &amp; {0} &amp; {9} \\ {0} &amp; {1} &amp; {1 8} \\ \\end{array} \\right)\n$$</p>\n<p>both contain the same information: $\\mathrm{\\ensuremath{x}}=9, \\ \\mathrm{y}=1 8.$ </p>\n<p>Two augmented matrices corresponding to linear systems that actually have $\\mathrm{S}$ olutions are said to be (row) equivalent if they have the same solutions. To denote this, we write:</p>\n<p>Suppose I have a large pile of equivalent fractions, such as 2/4, 27/54, 100/200,\nand so on. Most people will agree that their favorite way to write the number\nrepresented by all these different factors is $1 / 2$ , in which the numerator and\ndenominator are relatively prime. We usually call this a reduced fraction. This is an example of a canonical form, which is an extremely impressive way of saying"
        },
        {
            "id": 11,
            "content": "\"favorite way of writing it down'. There's a theorem telling us that every rational number can be specified by a unique fraction whose numerator and denominator are relatively prime. To say that again, but slower, every rational number has a\nreduced fraction, and furthermore, that reduced fraction is unique.</p>\n<p>$\\mathrm{S}$ ince there are many different augmented matrices that have the same set of solutions, we should find a canonical form for writing our augmented matrices. This canonical form is called Reduced Row Echelon Form, or RREF for short. RREF looks like this in general:</p>\n<p>The first non-zero entry in cach row is called the pivot. The asterisks denote\narbitrary content which could be several columns long. The following properties describe the RREF.</p>\n<p>$$\n\\left( \\begin{matrix} {1} &amp; {1} \\ {2} &amp; {-1} \\ \\end{matrix} \\right| \\begin{matrix} {2 7} \\ {0} \\ \\end{matrix} ) \\sim\\left( \\begin{matrix} {1} &amp; {0} \\ {0} &amp; {1} \\ \\end{matrix} \\begin{matrix} {9} \\ {1 8} \\ \\end{matrix} \\right)\n$$</p>\n<p>Here, - means \"'is equivalent to'.</p>\n<p>$$\n\\mathrm{A \\ l i t l e \\ p h i l o s o p h y :}\n$$</p>\n<h2>Time to define Reduced Row Echelon Form (RREF)</h2>\n<p>$$"
        },
        {
            "id": 12,
            "content": "<p>$$\n\\left( \\begin{matrix} {1} &amp; {<em>} &amp; {0} &amp; {</em>} &amp; {0} &amp; {\\cdots} &amp; {0} &amp; {b^{1}} \\ {0} &amp; {<em>} &amp; {1} &amp; {</em>} &amp; {0} &amp; {\\cdots} &amp; {0} &amp; {b^{2}} \\ {0} &amp; {*} &amp; {0} &amp; {} &amp; {1} &amp; {\\cdots} &amp; {0} &amp; {b^{3}} \\ {\\vdots} &amp; {} &amp; {\\vdots} &amp; {} &amp; {\\vdots} &amp; {} &amp; {0} &amp; {\\vdots} \\ {} &amp; {} &amp; {} &amp; {} &amp; {} &amp; {} &amp; {1} &amp; {b^{k}} \\ {0} &amp; {0} &amp; {} &amp; {} &amp; {} &amp; {} &amp; {0} &amp; {0} \\ {\\vdots} &amp; {\\vdots} &amp; {\\vdots} &amp; {\\vdots} &amp; {} &amp; {\\vdots} &amp; {\\vdots} \\ {0} &amp; {0} &amp; {0} &amp; {\\cdots} &amp; {0} &amp; {0} \\end{matrix} \\right)\n$$</p>\n<ol>\n<li>In RREF, the pivot of any row is always $1$ . $2$ . The pivot of any given row is always to the right of the pivot of the row aboveit. $3$ . The pivot is the only non-zero entry in its column.</li>\n</ol>\n<p>We can use Gauss-Jordan elimination to solve for ${\\mathrm{X, y}}$ , and $\\mathbf{z}$ . First, we represent the equations as an augmented matrix, for brevity.</p>"
        },
        {
            "id": 13,
            "content": "<p>The first row already has a leading l, and we can use it to zero out the rest of the first column. We subtract 3 times the first row from the second row, and $5$ times the first row from the third.</p>\n<p>Then we divide $\\mathrm{b y-5}$ in the second row, and add 6 times that to the third row to zero out its second column:</p>\n<p>Let's take another example:</p>\n<p>$$\n\\begin{array} {r c l} {x+y-z} &amp; {=} &amp; {0} \\ {3 x-2 y+2 z} &amp; {=} &amp; {5} \\ {5 x-y-z} &amp; {=} &amp; {0} \\end{array}\n$$</p>\n<p>$$\n\\left( \\begin{matrix} {1} &amp; {1} &amp; {-1} &amp; {0} \\ {3} &amp; {-2} &amp; {2} &amp; {5} \\ {5} &amp; {-1} &amp; {-1} &amp; {0} \\ \\end{matrix} \\right)\n$$</p>\n<p>$$\n\\left( \\begin{matrix} {1} &amp; {1} &amp; {-1} &amp; {0} \\ {0} &amp; {-5} &amp; {5} &amp; {5} \\ {0} &amp; {-6} &amp; {4} &amp; {0} \\ \\end{matrix} \\right)\n$$</p>\n<p>$$\n\\left( \\begin{matrix} {1} &amp; {1} &amp; {-1} &amp; {0} \\ {0} &amp; {1} &amp; {-1} &amp; {-1} \\ {0} &amp; {0} &amp; {-2} &amp; {-6} \\ \\end{matrix} \\right)\n$$</p>\n<p>We divide the last row $\\mathrm{b y-2}$ to reach the halfway point, with 1's on the diagonal and 0's below:</p>"
        },
        {
            "id": 14,
            "content": "<p>We can now zero the last column everywhere above the last row by adding the last row to each other row:</p>\n<p>And finally, we zero out the 1 in the middle column in the top row by adding the negative of the second row.</p>\n<p>So this results in the solution $\\mathrm{x=1, ~ y=2, ~ z=3 ~}$ . Substituting these values into the original equations shows that they work; for example, $\\mathrm{x+y-z=3}$ checks out with $1+2-3=0.$ </p>\n<p>In an age of computers, it's not as necessary to perform Gauss-Jordan climination by hand. But, knowing how it works will help us understand some of the material later. It's important to remember, for example, that all matrices that can be\ntransformed into each other using the three Gauss-Jordan operations will still all have the same solutions in the end - that we can perform any of those operations in any order and ultimately arrive at the same final solution. That fact may be more important than the algorithm itself.</p>\n<p>$$\n\\left( \\begin{matrix} {1} &amp; {1} &amp; {-1} &amp; {0} \\ {0} &amp; {1} &amp; {-1} &amp; {-1} \\ {0} &amp; {0} &amp; {1} &amp; {3} \\ \\end{matrix} \\right)\n$$</p>\n<p>$$"
        },
        {
            "id": 15,
            "content": "<p>$$\n\\left( \\begin{matrix} {1} &amp; {1} &amp; {0} &amp; {3} \\ {0} &amp; {1} &amp; {0} &amp; {2} \\ {0} &amp; {0} &amp; {1} &amp; {3} \\ \\end{matrix} \\right)\n$$</p>\n<p>$$\n\\left( \\begin{matrix} {1} &amp; {0} &amp; {0} &amp; {1} \\ {0} &amp; {1} &amp; {0} &amp; {2} \\ {0} &amp; {0} &amp; {1} &amp; {3} \\ \\end{matrix} \\right)\n$$</p>\n<p>It isn't necessarily the case that there is one unicue solution to a system of linear equations. In general, three cases are possible:</p>\n<p>There are no solutions, because the cquations are not logically consistent with each other. An easy example would be one equation that says $\\mathrm{x+y}=1,$ and another that says $\\mathbf{x+y}=0$ . These statements can't both be true.\n(Equations may contradict each other in less obvious ways.)</p>"
        },
        {
            "id": 16,
            "content": "<p>There are an infinite number of solutions. The linear ecuations still constrain the space of possible solutions, but they don't impose enough constraints to narrow things down to a single unique solution. This can happen if, for example, we have the equations $\\mathrm{x+y}=1$ and $2 \\mathrm{X} \\,+\\, 2 \\mathrm{y} \\,=\\, 2$ . Normally two equations describe lines that intersect at a point, but here, they really describe the same line.</p>\n<p>When we're done applying Gauss-Jordan elimination, we can tell which of these cases applies.</p>\n<p>If Gauss-Jordan elimination results in a row of all zeros, except for the number on the right-hand side of the augmented matrix, then there are no solutions. $\\mathrm{F}$ or example, consider the augmented matrix:</p>\n<h2>Solution Set for a System of Linear Equations</h2>\n<p>The third case is the one in our previous examples: exactly one solution.</p>\n<h2>How doweknow which caseit is??</h2>\n<p>$$\n\\left( \\begin{matrix} {1} &amp; {1} &amp; {1} \\ {2} &amp; {2} &amp; {1} \\ \\end{matrix} \\right)\n$$</p>\n<p>Gauss-Jordan elimination turns this into:</p>"
        }
    ]
}